version: '3'
services:
  mongo:
    image: mongo
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example
    ports:
      - 27017:27017
  postgres:
    image: postgres
    restart: always
    environment:
      POSTGRES_DB: esp
      POSTGRES_PASSWORD: example
    ports:
      - "5432:5432"
  zookeeper:
    image: 'bitnami/zookeeper:latest'
    ports:
      - '2181:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
  kafka:
    image: 'bitnami/kafka:latest'
    ports:
      - '9092:9092'
      - '9093:9093'
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka:9092,EXTERNAL://localhost:9093
      - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
    depends_on:
      - zookeeper
  event-generator:
    build:
      dockerfile: ./docker/Dockerfile
      context: ./
    volumes:
      - ./:/usr/src/app
    stdin_open: true
    environment:
      - HTTP_PROXY=http://126.179.0.206:9090
      - HTTPS_PROXY=http://126.179.0.206:9090
  event-receiver:
    build:
      dockerfile: ./docker/Dockerfile
      context: ./
    volumes:
      - ./:/usr/src/app
    command:
      - "python"
      - "./app/EventReceiver.py"
    environment:
      PYTHONPATH: "/usr/src/app/"
  spark:
    build:
      dockerfile: ./docker/Dockerfile
      context: ./
    volumes:
      - ./:/usr/src/app
    command:
      - "/usr/local/lib/python3.10/site-packages/pyspark/bin/spark-submit"
      - "--packages"
      - "org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0"
      - "./app/Spark.py"
    environment:
      PYTHONPATH: "/usr/src/app/"
  grafana:
    image: grafana/grafana-enterprise:8.2.0
    ports:
      - "3000:3000"
    user: '104'
    volumes:
      - ./grafana_data:/var/lib/grafana
